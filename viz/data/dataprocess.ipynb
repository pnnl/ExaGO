{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "usXoscPSaIME"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from shapely.geometry import shape\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h6gb52J1aIMI"
      },
      "outputs": [],
      "source": [
        "#generate point file: point name aligns with linstring source and target name\n",
        "f = open('case_ACTIVSg10k point.json')\n",
        "data = json.load(f)\n",
        "points = []\n",
        "for feature in data:\n",
        "    if feature['geometry']['type'] == 'Point':\n",
        "        geo = shape(feature[\"geometry\"])\n",
        "        p = feature[\"properties\"]\n",
        "        # kvlevels = p[\"KVlevels\"].replace(\"[\", \"{\")\n",
        "        # kvlevels = kvlevels.replace(\"]\", \"}\")\n",
        "        points.append({\n",
        "            \"wkt\":geo.wkt,\n",
        "            \"bus_name\": p[\"NAME\"],\n",
        "            \"kilovolt levels\": p[\"KVlevels\"],\n",
        "            \"number of buses\":p[\"nbus\"],\n",
        "            \"vm\":p[\"Vm\"],\n",
        "            \"start\":p[\"start\"],\n",
        "        })\n",
        "\n",
        "\n",
        "\n",
        "keys = points[0].keys()\n",
        "\n",
        "with open('10k_bus_7_26.csv', 'w', newline='') as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RIxvkjPNaIMN"
      },
      "outputs": [],
      "source": [
        "# assign id to combined points\n",
        "\n",
        "# df = pd.read_csv('10k_bus_7_26.csv')\n",
        "# df['id'] = df.groupby(['wkt']).ngroup()\n",
        "# df['id'] = df['bus_name'].map(str) + \"_\" +df['id'].map(str)\n",
        "# df.to_csv('10k_bus_id_7_26.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0PG5fSd1aIMP"
      },
      "outputs": [],
      "source": [
        "# update point id in us file\n",
        "\n",
        "# df = pd.read_csv('/content/drive/MyDrive/23 summer pnnl/new_all_bus_id_7_25.csv')\n",
        "# f = open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all point.json')\n",
        "# pointsdata = json.load(f)\n",
        "\n",
        "# for point in pointsdata:\n",
        "#     src = str(point['geometry']['coordinates'][0]) + ' '+ str(point['geometry'][\"coordinates\"][1])\n",
        "#     result = df.loc[df['wkt'] == src, 'id']\n",
        "#     if(len(result.index)>0):\n",
        "#         point['properties']['NAME'] = result.iloc[0]\n",
        "#     # df[df.wkt == src].iloc[0].id\n",
        "# with open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all point new name.json', 'w') as f:\n",
        "#     json.dump(pointsdata, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6UKG6TIYaIMG"
      },
      "outputs": [],
      "source": [
        "def getGeneration(data):\n",
        "    Geni = None\n",
        "    Gens = []\n",
        "    minPg = 1000.0\n",
        "    maxPg = 0.0\n",
        "    Pgcoal = 0.0\n",
        "    Pghydro = 0.0\n",
        "    Pgnuclear = 0.0\n",
        "    Pgng = 0.0\n",
        "    Pgsolar = 0.0\n",
        "    Pgwind = 0.0\n",
        "    Pgother = 0.0\n",
        "    Pgcoalcap = 0.0\n",
        "    Pghydrocap = 0.0\n",
        "    Pgnuclearcap = 0.0\n",
        "    Pgngcap = 0.0\n",
        "    Pgsolarcap = 0.0\n",
        "    Pgwindcap = 0.0\n",
        "    Pgothercap = 0.0\n",
        "\n",
        "    for feature in data:\n",
        "        if feature['geometry']['type'] == 'Point':\n",
        "            subst = feature['properties']\n",
        "            name = subst['NAME']\n",
        "            nbus = subst['nbus']\n",
        "            Pg = 0.0\n",
        "            Pcap = 0.0\n",
        "            gen_fuel = ''\n",
        "            ngen = 0\n",
        "            KV = []\n",
        "            for bus in subst['bus']:\n",
        "                KV.append(bus['BASE_KV'])\n",
        "                \n",
        "                for gen in bus['gen']:\n",
        "                    Pg += gen['GEN_STATUS'] * gen['PG']\n",
        "                    Pcap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    gen_fuel = gen['GEN_FUEL'].lower()\n",
        "\n",
        "                    if gen_fuel == 'wind':\n",
        "                        Pgwind += gen['GEN_STATUS'] * gen['PG']\n",
        "                        Pgwindcap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    elif gen_fuel == 'solar':\n",
        "                        Pgsolar += gen['GEN_STATUS'] * gen['PG']\n",
        "                        Pgsolarcap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    elif gen_fuel == 'coal':\n",
        "                        Pgcoal += gen['GEN_STATUS'] * gen['PG']\n",
        "                        Pgcoalcap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    elif gen_fuel == 'nuclear':\n",
        "                        Pgnuclear += gen['GEN_STATUS'] * gen['PG']\n",
        "                        Pgnuclearcap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    elif gen_fuel == 'hydro':\n",
        "                        Pghydro += gen['GEN_STATUS'] * gen['PG']\n",
        "                        Pghydrocap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    elif gen_fuel == 'ng':\n",
        "                        Pgng += gen['GEN_STATUS'] * gen['PG']\n",
        "                        Pgngcap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    else:\n",
        "                        Pgother += gen['GEN_STATUS'] * gen['PG']\n",
        "                        Pgothercap += gen['GEN_STATUS'] * gen['PMAX']\n",
        "                    ngen += 1\n",
        "\n",
        "            if ngen:\n",
        "                color = ''\n",
        "                if gen_fuel == 'wind':\n",
        "                    color = 'green'\n",
        "                elif gen_fuel == 'solar':\n",
        "                    color = 'yellow'\n",
        "                elif gen_fuel == 'coal':\n",
        "                    color = 'gray'\n",
        "                elif gen_fuel == 'nuclear':\n",
        "                    color = 'red'\n",
        "                elif gen_fuel == 'hydro':\n",
        "                    color = 'blue'\n",
        "                elif gen_fuel == 'ng':\n",
        "                    color = 'orange'\n",
        "                else:\n",
        "                    color = 'black'\n",
        "\n",
        "                if Pg <= minPg:\n",
        "                    minPg = Pg\n",
        "                if Pg >= maxPg:\n",
        "                    maxPg = Pg\n",
        "                geo = shape(feature[\"geometry\"])\n",
        "                Geni = { \"coordinates\": geo.wkt, \"Pg\": Pg, \"Pcap\": Pcap, \"KVlevels\": KV, \"color\": color, \"name\":name, \"nbus\": nbus, \"type\": gen_fuel }\n",
        "                Gens.append(Geni)\n",
        "    return { \"minPg\": minPg, \"maxPg\": maxPg, \"Gens\": Gens, \"Pgwind\": Pgwind, \"Pgsolar\": Pgsolar, \"Pgnuclear\": Pgnuclear, \"Pghydro\": Pghydro, \"Pgng\": Pgng, \"Pgcoal\": Pgcoal, \"Pgother\": Pgother, \"Pgwindcap\": Pgwindcap, \"Pgsolarcap\": Pgsolarcap, \"Pgnuclearcap\": Pgnuclearcap, \"Pghydrocap\": Pghydrocap, \"Pgngcap\": Pgngcap, \"Pgcoalcap\": Pgcoalcap, \"Pgothercap\": Pgothercap }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XyhT47OnaIML"
      },
      "outputs": [],
      "source": [
        "\n",
        "f = open('case_ACTIVSg10k point.json')\n",
        "data = json.load(f)\n",
        "gendata = getGeneration(data)\n",
        "\n",
        "keys = gendata['Gens'][0].keys()\n",
        "\n",
        "with open('10k_generation_7_26.csv', 'w', newline='') as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(gendata['Gens'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# update transmission line with source, target and actual flow \n",
        "f = open('case_ACTIVSg10k line.json')\n",
        "data = json.load(f)\n",
        "lines = []\n",
        "for feature in data:\n",
        "    geo = shape(feature[\"geometry\"])\n",
        "    p = feature[\"properties\"]\n",
        "    # kvlevels = p[\"KVlevels\"].replace(\"[\", \"{\")\n",
        "    # kvlevels = kvlevels.replace(\"]\", \"}\")\n",
        "    x = p[\"NAME\"].split(' -- ')\n",
        "    if(p['PF']>0):\n",
        "        lines.append({\n",
        "            \"wkt\":geo.wkt,\n",
        "            \"flow capacity\":p[\"RATE_A\"],\n",
        "            \"pf\":p[\"PF\"],\n",
        "            \"qf\":p[\"QF\"],\n",
        "            \"pt\":p[\"PT\"],\n",
        "            \"qt\":p[\"QT\"],\n",
        "            \"kilovolt\": p[\"KV\"],\n",
        "            \"line_name\": p[\"NAME\"],\n",
        "            \"srouce\": x[0],\n",
        "            \"target\": x[1],\n",
        "            \"actual flow\":abs(p[\"PF\"]),\n",
        "            \n",
        "\n",
        "        })\n",
        "    else:\n",
        "        lines.append({\n",
        "            \"wkt\":geo.wkt,\n",
        "            \"flow capacity\":p[\"RATE_A\"],\n",
        "            \"pf\":p[\"PF\"],\n",
        "            \"qf\":p[\"QF\"],\n",
        "            \"pt\":p[\"PT\"],\n",
        "            \"qt\":p[\"QT\"],\n",
        "            \"kilovolt\": p[\"KV\"],\n",
        "            \"line_name\": p[\"NAME\"],\n",
        "            \"srouce\": x[1],\n",
        "            \"target\": x[0],\n",
        "            \"actual flow\":abs(p[\"PF\"]),\n",
        "        })\n",
        "\n",
        "\n",
        "\n",
        "keys = lines[0].keys()\n",
        "\n",
        "with open('10k_transmission_line_7_27.csv', 'w', newline='') as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jvYcP_hKaIMN"
      },
      "outputs": [],
      "source": [
        "# change line name to uniqe point id\n",
        "df = pd.read_csv('/content/drive/MyDrive/23 summer pnnl/new_all_bus_id_7_25.csv')\n",
        "f = open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all line.json')\n",
        "linedata = json.load(f)\n",
        "# lines = []\n",
        "# df['temp_wkt'] = df['wkt'].map(str).replace(\"POINT (\", '')\n",
        "# df['temp_wkt'] = df['temp_wkt'].map(str).replace(')','')\n",
        "for line in linedata:\n",
        "    # print(line['geometry']['coordinates'][0])+\n",
        "    src = str(line['geometry']['coordinates'][0][0]) + ' '+ str(line['geometry'][\"coordinates\"][0][1])\n",
        "    det = str(line['geometry'][\"coordinates\"][1][0]) + ' '+ str(line['geometry'][\"coordinates\"][1][1])\n",
        "    if(float(line['properties']['PF'])>0):\n",
        "        sresult = df.loc[df['wkt'] == src, 'id']\n",
        "        tresult = df.loc[df['wkt'] == det, 'id']\n",
        "        if(len(sresult.index)>0 and len(tresult.index)>0):\n",
        "          line['properties']['source'] = sresult.iloc[0]\n",
        "          line['properties']['target'] = tresult.iloc[0]\n",
        "          line['properties']['NAME'] = line['properties']['source'] + ' -- ' + line['properties']['target']\n",
        "    else:\n",
        "        sresult = df.loc[df['wkt'] == src, 'id']\n",
        "        tresult = df.loc[df['wkt'] == det, 'id']\n",
        "        if(len(sresult.index)>0 and len(tresult.index)>0):\n",
        "          line['properties']['target'] = sresult.iloc[0]\n",
        "          line['properties']['source'] = tresult.iloc[0]\n",
        "          line['properties']['NAME'] = line['properties']['target'] + ' -- ' + line['properties']['source']\n",
        "\n",
        "with open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all line new name.json', 'w') as f:\n",
        "    json.dump(linedata, f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qbHpQ2A0nKks"
      },
      "outputs": [],
      "source": [
        "linejson = {\n",
        "      \"type\": \"FeatureCollection\",\n",
        "      \"features\":linedata\n",
        "    }\n",
        "with open('/content/drive/MyDrive/23 summer pnnl/qgis all line new name.json', 'w') as f:\n",
        "    json.dump(linejson, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gP8B1KFJkDYM"
      },
      "outputs": [],
      "source": [
        "\n",
        "f = open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all temp.json')\n",
        "alldata = json.load(f)\n",
        "alldata['geojsondata']['features'] = linedata + pointsdata\n",
        "alldata['nbus'] = len(pointsdata)\n",
        "alldata['nbranch'] = len(linedata)\n",
        "with open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all.json', 'w') as f:\n",
        "    json.dump(alldata, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqJMqDhVdp9x"
      },
      "outputs": [],
      "source": [
        "# keys = lines[0].keys()\n",
        "\n",
        "# with open('/content/drive/MyDrive/23 summer pnnl/all_line_id_7_24.csv', 'w', newline='') as output_file:\n",
        "#     dict_writer = csv.DictWriter(output_file, keys)\n",
        "#     dict_writer.writeheader()\n",
        "#     dict_writer.writerows(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "p_2TKr7b-itk"
      },
      "outputs": [],
      "source": [
        "# combine 2000 dataset with other dataset\n",
        "f70k = open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg70k list.json')\n",
        "d70k = json.load(f70k)\n",
        "\n",
        "f10k = open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg10k list.json')\n",
        "d10k = json.load(f10k)\n",
        "f2000 = open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg2000 list.json')\n",
        "d2000 = json.load(f2000)\n",
        "\n",
        "\n",
        "p70 = [d for d in d70k if d['geometry']['type'] == 'Point']\n",
        "p10 = [d for d in d10k if d['geometry']['type'] == 'Point']\n",
        "p2000 = [d for d in d2000 if d['geometry']['type'] == 'Point']\n",
        "points = p70 + p10\n",
        "points = points + p2000\n",
        "with open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all point.json', 'w') as f:\n",
        "    json.dump(points, f)\n",
        "\n",
        "l70 = [d for d in d70k if d['geometry']['type'] == 'LineString']\n",
        "l10 = [d for d in d10k if d['geometry']['type'] == 'LineString']\n",
        "l2000 = [d for d in d2000 if d['geometry']['type'] == 'LineString']\n",
        "lines = l70 + l10\n",
        "lines = lines + l2000\n",
        "with open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all line.json', 'w') as f:\n",
        "    json.dump(lines, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "n2a_FbyeE0mS"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/23 summer pnnl/case_ACTIVSg all point.json', 'w') as f:\n",
        "    json.dump(points, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pjtXBqR0eJs"
      },
      "outputs": [],
      "source": [
        "#generate line csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "muQyfL9kaIMM"
      },
      "outputs": [],
      "source": [
        "# transmission line process\n",
        "# generate source and target info of transmission lines, make pf value absolute\n",
        "#remove linestring where the end and start point is the same, because it's not valid to perform bigquery\n",
        "import csv\n",
        "input = open('/content/drive/MyDrive/23 summer pnnl/all_line_part_attribute_db_7_25.csv', 'rt')\n",
        "output = open('/content/drive/MyDrive/23 summer pnnl/all_line_db_7_26.csv', 'w', newline='')\n",
        "writer = csv.writer(output)\n",
        "reader = csv.reader(input)\n",
        "headers = next(reader, None)  # returns the headers or `None` if the input is empty\n",
        "if headers:\n",
        "    headers.append('actual flow')\n",
        "    writer.writerow(headers)\n",
        "for row in reader:\n",
        "    row.append(abs(float(row[2])))\n",
        "    writer.writerow(row)\n",
        "input.close()\n",
        "output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXH_qnCGaIMM"
      },
      "outputs": [],
      "source": [
        "# generate text from point table\n",
        "# Geni = { \"coordinates\": geo.wkt, \"Pg\": Pg, \"Pcap\": Pcap, \"KVlevels\": KV, \"color\": color, \"name\":name, \"nbus\": nbus, \"type\": gen_fuel }\n",
        "with open('200point7_11.txt', 'a') as the_point_file:\n",
        "        the_point_file.write('This file lists a number of power grid generations and their information, including individual id, name, location cooridnates in WKT format (i.e., latitude and longitude), power produced, power capacity, voltage level, number of buses and category (e.g., wind, nuclear). Each line represents one generation.\\n')\n",
        "        for gen in gendata['Gens']:\n",
        "            strline = ( \"I am a \" + gen['type'] +\" generation. My name is \" + gen['name'] +\n",
        "                       \". My location coordinates is defined by \" + gen[\"coordinates\"] +\n",
        "                       \". The amount of power generated by me is \" + str(gen['Pg']) +\n",
        "                       \". My power capacity is \" + str(gen['Pcap']) +\n",
        "                       \". My voltage level range is \" + str(gen['KVlevels']) +\n",
        "                       \". I have \" + str(gen['nbus']) + \" buses.\\n\"\n",
        "                        )\n",
        "            the_point_file.write(strline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwm3R9eGaIMN"
      },
      "outputs": [],
      "source": [
        "#generate text from line table\n",
        "with open('200line7_11noloop.csv') as f:\n",
        "    linedata = [{k: v for k, v in row.items()}\n",
        "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
        "\n",
        "\n",
        "with open('200line7_11.txt', 'a') as the_line_file:\n",
        "    the_line_file.write('This file lists a number of power grid transmission lines and their information, including individual name, location cooridnates in WKT format (i.e., latitude and longitude of the source and target point), flow capacity, voltage level, actual flow. Each line represents one transimisson line. ' +\n",
        "                        'The trnasmission line name is defined by join its source and target node name with \\' -- \\'. '\n",
        "                        + 'If the PF value is positive, the first part of its name is the name of the source node and the second part of its name is the name of the target node ' +\n",
        "                        'If the PF value is negative, the first part of its name is the name of the target node and the second part of its name is the name of the source node\\n')\n",
        "    for line in linedata:\n",
        "        strline = ( \"I am a transmission line. My name is \" + line['NAME'] +\n",
        "                    \". My location coordinates is defined by \" + line[\"WKT\"] +\n",
        "                    \". My flow capacity is \" + str(line['RATE_A']) +\n",
        "                    \". My voltage level is \" + str(line['KV']) +\n",
        "                    \". The actual flow pass through me is \" + str(line['PF']) + \".\\n\"\n",
        "                    )\n",
        "        the_line_file.write(strline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDtHF8PwaIMM"
      },
      "outputs": [],
      "source": [
        "#remove linestring where the end and start point is the same, because it's not valid to perform bigquery\n",
        "import csv\n",
        "input = open('200line7_11.csv', 'rt')\n",
        "output = open('200line7_11noloop.csv', 'w', newline='')\n",
        "writer = csv.writer(output)\n",
        "reader = csv.reader(input)\n",
        "headers = next(reader, None)  # returns the headers or `None` if the input is empty\n",
        "if headers:\n",
        "    writer.writerow(headers)\n",
        "for row in reader:\n",
        "    x = row[1].split(\",\")\n",
        "    if x[0]!=x[1]:\n",
        "        row[1] = \"LINESTRING (\" + row[1] + \")\"\n",
        "        writer.writerow(row)\n",
        "input.close()\n",
        "output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add statename to county table \n",
        "import pandas as pd\n",
        "import us\n",
        "\n",
        "county_df = pd.read_csv('counties.csv')\n",
        "\n",
        "fips_to_name = us.states.mapping(\"fips\", \"name\")\n",
        "\n",
        "county_df[\"fips\"] = county_df[\"fips\"].map(str).str.zfill(2)\n",
        "county_df[\"states\"] = county_df[\"fips\"].map(fips_to_name)\n",
        "\n",
        "county_df.to_csv('county_name.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
