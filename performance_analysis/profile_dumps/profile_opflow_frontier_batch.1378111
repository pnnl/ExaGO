Resetting modules to system default. Reseting $MODULEPATH back to system default. All extra directories will be removed from $MODULEPATH.

The following have been reloaded with a version change:
  1) cray-mpich/8.1.25 => cray-mpich/8.1.23


Lmod is automatically replacing "cce/15.0.0" with "amd/5.3.0".


Lmod is automatically replacing "PrgEnv-cray/8.3.3" with "PrgEnv-amd/8.3.3".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-mpich/8.1.23


The following have been reloaded with a version change:
  1) amd/5.3.0 => amd/5.2.0


The following have been reloaded with a version change:
  1) cray-mpich/8.1.23 => cray-mpich/8.1.25

Auto Profiler Log ======> [[]]
Auto Profiler Log ======> For testcase 1
Auto Profiler Log ======> ['opflow', '-netfile', 'datafiles/case_ACTIVSg200.m', '-print_output', '0', '-log_view', '-opflow_solver', 'HIOP', '-opflow_model', 'POWER_BALANCE_HIOP']
Auto Profiler Log ======> ----
[ExaGO] Creating OPFlow

[Warning] Hiop will ignore value 'auto' set for option 'compute_mode' at runtime since this option is already specified in the option file.
[Warning] Hiop will ignore value '0' set for option 'verbosity_level' at runtime since this option is already specified in the option file.
[Warning] Detected 1 fixed variables out of a total of 476.
===============
Hiop SOLVER
===============
Using 1 MPI ranks.
---------------
Problem Summary
---------------
Total number of variables: 476
     lower/upper/lower_and_upper bounds: 277 / 277 / 277
Total number of equality constraints: 400
Total number of inequality constraints: 490
     lower/upper/lower_and_upper bounds: 490 / 490 / 490
iter    objective     inf_pr     inf_du   lg(mu)  alpha_du   alpha_pr linesrch
   0  4.0417248e+04 3.699e+00  2.322e+03  -1.00  0.000e+00  0.000e+00  -(-)
   1  3.8736643e+04 3.695e+00  2.319e+03  -1.00  1.328e-03  1.308e-03  1(s)
   2  3.8320137e+04 3.689e+00  2.316e+03  -1.00  8.553e-04  1.571e-03  1(s)
   3  3.7670495e+04 3.682e+00  2.312e+03  -1.00  1.417e-03  2.003e-03  1(s)
   4  3.7501975e+04 3.669e+00  2.286e+03  -1.00  2.196e-02  3.335e-03  1(s)
   5  3.6429919e+04 3.629e+00  2.260e+03  -1.00  1.127e-02  1.094e-02  1(s)
   6  3.6096353e+04 3.591e+00  2.186e+03  -1.00  9.403e-02  1.071e-02  1(s)
   7  3.5511492e+04 3.425e+00  3.470e+03  -1.00  3.461e-01  4.604e-02  1(s)
   8  3.5414659e+04 3.420e+00  3.929e+03  -1.00  1.549e-03  1.168e-03  1(s)
   9  3.5216589e+04 3.343e+00  3.481e+03  -1.00  2.280e-03  2.239e-02  1(s)
iter    objective     inf_pr     inf_du   lg(mu)  alpha_du   alpha_pr linesrch
  10  3.4883502e+04 3.264e+00  3.059e+03  -1.00  6.807e-03  2.360e-02  1(s)
  11  3.4347726e+04 3.156e+00  2.991e+03  -1.00  1.459e-03  3.310e-02  1(s)
  12  3.4292164e+04 3.129e+00  2.969e+03  -1.00  2.577e-02  8.475e-03  1(s)
  13  3.4186682e+04 3.083e+00  2.936e+03  -1.00  3.983e-02  1.475e-02  1(s)
  14  3.4116849e+04 2.992e+00  2.931e+03  -1.00  8.184e-02  2.954e-02  1(s)
  15  3.3895406e+04 2.702e+00  3.310e+03  -1.00  1.594e-02  9.684e-02  1(s)
  16  3.3877456e+04 2.688e+00  3.287e+03  -1.00  4.210e-03  5.361e-03  1(s)
  17  3.3696046e+04 2.580e+00  3.318e+03  -1.00  9.531e-03  3.991e-02  1(s)
  18  3.3464804e+04 2.441e+00  3.322e+03  -1.00  9.278e-03  5.360e-02  1(s)
  19  3.3172636e+04 2.252e+00  2.908e+03  -1.00  3.058e-02  7.749e-02  1(s)
iter    objective     inf_pr     inf_du   lg(mu)  alpha_du   alpha_pr linesrch
  20  3.2760844e+04 1.940e+00  2.738e+03  -1.00  4.595e-02  1.383e-01  1(s)
Maximum number of iterations reached.
Total time 16.166s
Hiop internal time:     total 16.417s      avg iter 0.821s
    internal total std dev across ranks 0.000 percent
Fcn/deriv time:     total=0.019s  ( obj=0.000 grad=0.000 cons=0.001 Jac=0.005 Hess=0.013)
    Fcn/deriv total std dev across ranks 0.000 percent
Fcn/deriv #: obj 22 grad 22 eq cons 22 ineq cons 22 eq Jac 22 ineq Jac 22
Total KKT time 16.142s
	update init 0.500s     update linsys 0.080s     fact 14.564s
	solve rhs-manip 0.001s    inner solve 1.244s    resid 0.023s    IR 34.500iters

****************************************************************************************************************************************************************
***                                WIDEN YOUR WINDOW TO 160 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document                                 ***
****************************************************************************************************************************************************************

------------------------------------------------------------------ PETSc Performance Summary: ------------------------------------------------------------------

opflow on a  named frontier08059 with 1 processor, by sayefsakin Thu Jul 13 13:43:12 2023
Using Petsc Release Version 3.18.6, Mar 30, 2023

                         Max       Max/Min     Avg       Total
Time (sec):           1.833e+01     1.000   1.833e+01
Objects:              6.300e+01     1.000   6.300e+01
Flops:                4.029e+07     1.000   4.029e+07  4.029e+07
Flops/sec:            2.198e+06     1.000   2.198e+06  2.198e+06
MPI Msg Count:        0.000e+00     0.000   0.000e+00  0.000e+00
MPI Msg Len (bytes):  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flops
                            and VecAXPY() for complex vectors of length N --> 8N flops

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.5292e-03   0.0%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 1:    Reading Data: 1.0113e-02   0.1%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 2:          Set up: 2.1461e+00  11.7%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 3:           Solve: 1.6169e+01  88.2%  4.0288e+07 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage


--- Event Stage 1: Reading Data


--- Event Stage 2: Set up

DMCreateMat            1 1.0 3.2867e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexBuFrCeLi         1 1.0 1.9383e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexStratify         1 1.0 9.8519e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexSymmetrize       1 1.0 1.4378e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexPrealloc         1 1.0 2.6444e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMNtLayoutSetUp        1 1.0 5.2800e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMNtSetUp              1 1.0 1.6618e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetGraph             1 1.0 3.6100e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 2 1.0 1.5549e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       1 1.0 2.6000e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         1 1.0 1.1983e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0

--- Event Stage 3: Solve

OPFLOWGrad            22 1.0 1.0101e-05 1.0 5.02e+03 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   497
OPFLOWEqCons          22 1.0 5.1585e-04 1.0 9.63e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  2  0  0  0  1866
OPFLOWIneqCons        22 1.0 4.2421e-04 1.0 1.03e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   0  3  0  0  0  2440
OPFLOWSolve            1 1.0 1.6169e+01 1.0 4.03e+07 1.0 0.0e+00 0.0e+00 0.0e+00 88 100  0  0  0 100 100  0  0  0     2
Auto Profiler Log ======> solver line found
OPFLOWDenseHess       21 1.0 1.2691e-02 1.0 3.03e+07 1.0 0.0e+00 0.0e+00 0.0e+00  0 75  0  0  0   0 75  0  0  0  2385
OPFLOWSparseHess      21 1.0 7.3820e-06 1.0 3.99e+03 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   541
OPFLOWDenseIneqConsJac      22 1.0 2.7572e-03 1.0 4.34e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 11  0  0  0   0 11  0  0  0  1576
OPFLOWDenseEqConsJac      22 1.0 2.2736e-03 1.0 3.67e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  9  0  0  0   0  9  0  0  0  1613
------------------------------------------------------------------------------------------------------------------------

Object Type          Creations   Destructions. Reports information only for process 0.

--- Event Stage 0: Main Stage

    Distributed Mesh     0              2
            DM Label     0              2
           Index Set     0              4
   IS L to G Mapping     0              1
             Section     0              5
   Star Forest Graph     0              5
     Discrete System     0              2
           Weak Form     0              2
    GraphPartitioner     0              1
              Vector     0             14
              Matrix     0              3
              Viewer     1              0

--- Event Stage 1: Reading Data


--- Event Stage 2: Set up

    Distributed Mesh     2              0
            DM Label     2              0
           Index Set    10              6
   IS L to G Mapping     1              0
             Section    15             10
   Star Forest Graph     7              2
     Discrete System     2              0
           Weak Form     2              0
    GraphPartitioner     1              0
              Vector    17              3
              Matrix     3              0

--- Event Stage 3: Solve

========================================================================================================================
Average time to get PetscTime(): 3.4e-08
#PETSc Option Table entries:
-log_view
-netfile datafiles/case_ACTIVSg200.m
-opflow_model POWER_BALANCE_HIOP
-opflow_solver HIOP
-print_output 0
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --prefix=/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45 --with-ssl=0 --download-c2html=0 --download-sowing=0 --download-hwloc=0 --with-make-exec=make --with-cc=/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicc --with-cxx=/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicxx --with-fc=/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpif90 --with-precision=double --with-scalar-type=real --with-shared-libraries=1 --with-debugging=0 --with-openmp=0 --with-64-bit-indices=0 --with-blaslapack-lib=/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/openblas-0.3.20-qphkv5qzud65a5duvaqxi5zvb5rc4lzf/lib/libopenblas.so --with-x=0 --with-clanguage=C --with-cuda=0 --with-hip=0 --with-metis=0 --with-hypre=0 --with-parmetis=0 --with-kokkos=0 --with-kokkos-kernels=0 --with-superlu_dist=0 --with-ptscotch=0 --with-suitesparse=0 --with-hdf5=0 --with-zlib=0 --with-mumps=0 --with-trilinos=0 --with-fftw=0 --with-valgrind=0 --with-gmp=0 --with-libpng=0 --with-giflib=0 --with-mpfr=0 --with-netcdf=0 --with-pnetcdf=0 --with-moab=0 --with-random123=0 --with-exodusii=0 --with-cgns=0 --with-memkind=0 --with-p4est=0 --with-saws=0 --with-yaml=0 --with-hwloc=0 --with-libjpeg=0 --with-scalapack=0 --with-strumpack=0 --with-mmg=0 --with-parmmg=0 --with-tetgen=0
-----------------------------------------
Libraries compiled on 2023-07-04 20:14:54 on frontier01532
Machine characteristics: Linux-5.14.21-150400.24.46_12.0.72-cray_shasta_c-x86_64-with-glibc2.31
Using PETSc directory: /lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45
Using PETSc arch:
-----------------------------------------

Using C compiler: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-unknown-pragmas -fstack-protector -Qunused-arguments -fvisibility=hidden -g -O3
Using Fortran compiler: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpif90  -fPIC -O
-----------------------------------------

Using include paths: -I/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45/include
-----------------------------------------

Using C linker: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicc
Using Fortran linker: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpif90
Using libraries: -Wl,-rpath,/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45/lib -L/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45/lib -lpetsc -Wl,-rpath,/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/openblas-0.3.20-qphkv5qzud65a5duvaqxi5zvb5rc4lzf/lib -L/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/openblas-0.3.20-qphkv5qzud65a5duvaqxi5zvb5rc4lzf/lib -Wl,-rpath,/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/lib -L/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/lib -Wl,-rpath,/usr/lib64/gcc/x86_64-suse-linux/7 -L/usr/lib64/gcc/x86_64-suse-linux/7 -Wl,-rpath,/usr/x86_64-suse-linux/lib -L/usr/x86_64-suse-linux/lib -Wl,-rpath,/opt/rocm-5.2.0/llvm/lib -L/opt/rocm-5.2.0/llvm/lib -lopenblas -lpthread -lm -lstdc++ -ldl -lmpifort_amd -lmpi_amd -lflangmain -lpgmath -lflang -lflangrti -lompstub -lm -lrt -lpthread -lgcc_s -lstdc++ -ldl
-----------------------------------------

Auto Profiler Log ======> opflow runs successfully
Auto Profiler Log ======> Total measured time with no tool: 19.86337 seconds.
Auto Profiler Log ======> With no tool Total Iterations: 1, GPU Average time per testcase: 19.86337 seconds, std: 0.0
Auto Profiler Log ======> PETSc reported Solve Time per testcase: 16.169 seconds
Auto Profiler Log ======> Total HIOP iterations: 20, Average time per HIOP iteration: 0.99317 seconds
Auto Profiler Log ======> PETSc reported Solve time per iteration: 0.80845
Auto Profiler Log ======> For testcase 2
Auto Profiler Log ======> ['opflow', '-netfile', 'datafiles/case_ACTIVSg200.m', '-print_output', '0', '-log_view', '-opflow_solver', 'HIOP', '-opflow_model', 'POWER_BALANCE_HIOP']
Auto Profiler Log ======> ----
[ExaGO] Creating OPFlow

[Warning] Hiop will ignore value 'auto' set for option 'compute_mode' at runtime since this option is already specified in the option file.
[Warning] Hiop will ignore value '0' set for option 'verbosity_level' at runtime since this option is already specified in the option file.
[Warning] Detected 1 fixed variables out of a total of 476.
===============
Hiop SOLVER
===============
Using 1 MPI ranks.
---------------
Problem Summary
---------------
Total number of variables: 476
     lower/upper/lower_and_upper bounds: 277 / 277 / 277
Total number of equality constraints: 400
Total number of inequality constraints: 490
     lower/upper/lower_and_upper bounds: 490 / 490 / 490
iter    objective     inf_pr     inf_du   lg(mu)  alpha_du   alpha_pr linesrch
   0  4.0417248e+04 3.699e+00  2.322e+03  -1.00  0.000e+00  0.000e+00  -(-)
   1  3.8736643e+04 3.695e+00  2.319e+03  -1.00  1.328e-03  1.308e-03  1(s)
   2  3.8320137e+04 3.689e+00  2.316e+03  -1.00  8.553e-04  1.571e-03  1(s)
   3  3.7670495e+04 3.682e+00  2.312e+03  -1.00  1.417e-03  2.003e-03  1(s)
   4  3.7501975e+04 3.669e+00  2.286e+03  -1.00  2.196e-02  3.335e-03  1(s)
   5  3.6429919e+04 3.629e+00  2.260e+03  -1.00  1.127e-02  1.094e-02  1(s)
   6  3.6096353e+04 3.591e+00  2.186e+03  -1.00  9.403e-02  1.071e-02  1(s)
   7  3.5511492e+04 3.425e+00  3.470e+03  -1.00  3.461e-01  4.604e-02  1(s)
   8  3.5414659e+04 3.420e+00  3.929e+03  -1.00  1.549e-03  1.168e-03  1(s)
   9  3.5216589e+04 3.343e+00  3.481e+03  -1.00  2.280e-03  2.239e-02  1(s)
iter    objective     inf_pr     inf_du   lg(mu)  alpha_du   alpha_pr linesrch
  10  3.4883502e+04 3.264e+00  3.059e+03  -1.00  6.807e-03  2.360e-02  1(s)
  11  3.4347726e+04 3.156e+00  2.991e+03  -1.00  1.459e-03  3.310e-02  1(s)
  12  3.4292164e+04 3.129e+00  2.969e+03  -1.00  2.577e-02  8.475e-03  1(s)
  13  3.4186682e+04 3.083e+00  2.936e+03  -1.00  3.983e-02  1.475e-02  1(s)
  14  3.4116849e+04 2.992e+00  2.931e+03  -1.00  8.184e-02  2.954e-02  1(s)
  15  3.3895406e+04 2.702e+00  3.310e+03  -1.00  1.594e-02  9.684e-02  1(s)
  16  3.3877456e+04 2.688e+00  3.287e+03  -1.00  4.210e-03  5.361e-03  1(s)
  17  3.3696046e+04 2.580e+00  3.318e+03  -1.00  9.531e-03  3.991e-02  1(s)
  18  3.3464804e+04 2.441e+00  3.322e+03  -1.00  9.278e-03  5.360e-02  1(s)
  19  3.3172636e+04 2.252e+00  2.908e+03  -1.00  3.058e-02  7.749e-02  1(s)
iter    objective     inf_pr     inf_du   lg(mu)  alpha_du   alpha_pr linesrch
  20  3.2760844e+04 1.940e+00  2.738e+03  -1.00  4.595e-02  1.383e-01  1(s)
Maximum number of iterations reached.
Total time 1.244s
Hiop internal time:     total 1.231s      avg iter 0.062s
    internal total std dev across ranks 0.000 percent
Fcn/deriv time:     total=0.018s  ( obj=0.000 grad=0.000 cons=0.001 Jac=0.005 Hess=0.012)
    Fcn/deriv total std dev across ranks 0.000 percent
Fcn/deriv #: obj 22 grad 22 eq cons 22 ineq cons 22 eq Jac 22 ineq Jac 22
Total KKT time 1.224s
	update init 0.009s     update linsys 0.055s     fact 1.094s
	solve rhs-manip 0.001s    inner solve 0.053s    resid 0.016s    IR 34.500iters

****************************************************************************************************************************************************************
***                                WIDEN YOUR WINDOW TO 160 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document                                 ***
****************************************************************************************************************************************************************

------------------------------------------------------------------ PETSc Performance Summary: ------------------------------------------------------------------

opflow on a  named frontier08059 with 1 processor, by sayefsakin Thu Jul 13 13:43:15 2023
Using Petsc Release Version 3.18.6, Mar 30, 2023

                         Max       Max/Min     Avg       Total
Time (sec):           1.385e+00     1.000   1.385e+00
Objects:              6.300e+01     1.000   6.300e+01
Flops:                4.029e+07     1.000   4.029e+07  4.029e+07
Flops/sec:            2.908e+07     1.000   2.908e+07  2.908e+07
MPI Msg Count:        0.000e+00     0.000   0.000e+00  0.000e+00
MPI Msg Len (bytes):  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flops
                            and VecAXPY() for complex vectors of length N --> 8N flops

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 5.2551e-04   0.0%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 1:    Reading Data: 6.7060e-03   0.5%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 2:          Set up: 1.3369e-01   9.7%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%
 3:           Solve: 1.2443e+00  89.8%  4.0288e+07 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage


--- Event Stage 1: Reading Data


--- Event Stage 2: Set up

DMCreateMat            1 1.0 3.4487e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexBuFrCeLi         1 1.0 1.1021e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexStratify         1 1.0 6.7430e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexSymmetrize       1 1.0 1.3315e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMPlexPrealloc         1 1.0 2.9042e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMNtLayoutSetUp        1 1.0 3.1989e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
DMNtSetUp              1 1.0 1.6789e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetGraph             1 1.0 1.5000e-07 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 2 1.0 4.7790e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       1 1.0 8.0000e-08 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         1 1.0 1.6141e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0

--- Event Stage 3: Solve

OPFLOWGrad            22 1.0 5.2600e-06 1.0 5.02e+03 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   954
OPFLOWEqCons          22 1.0 4.2999e-04 1.0 9.63e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  2  0  0  0  2239
OPFLOWIneqCons        22 1.0 4.0083e-04 1.0 1.03e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   0  3  0  0  0  2582
OPFLOWSolve            1 1.0 1.2443e+00 1.0 4.03e+07 1.0 0.0e+00 0.0e+00 0.0e+00 90 100  0  0  0 100 100  0  0  0    32
Auto Profiler Log ======> solver line found
OPFLOWDenseHess       21 1.0 1.2308e-02 1.0 3.03e+07 1.0 0.0e+00 0.0e+00 0.0e+00  1 75  0  0  0   1 75  0  0  0  2459
OPFLOWSparseHess      21 1.0 4.3220e-06 1.0 3.99e+03 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0   923
OPFLOWDenseIneqConsJac      22 1.0 2.6518e-03 1.0 4.34e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0 11  0  0  0   0 11  0  0  0  1638
OPFLOWDenseEqConsJac      22 1.0 2.1600e-03 1.0 3.67e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  9  0  0  0   0  9  0  0  0  1697
------------------------------------------------------------------------------------------------------------------------

Object Type          Creations   Destructions. Reports information only for process 0.

--- Event Stage 0: Main Stage

    Distributed Mesh     0              2
            DM Label     0              2
           Index Set     0              4
   IS L to G Mapping     0              1
             Section     0              5
   Star Forest Graph     0              5
     Discrete System     0              2
           Weak Form     0              2
    GraphPartitioner     0              1
              Vector     0             14
              Matrix     0              3
              Viewer     1              0

--- Event Stage 1: Reading Data


--- Event Stage 2: Set up

    Distributed Mesh     2              0
            DM Label     2              0
           Index Set    10              6
   IS L to G Mapping     1              0
             Section    15             10
   Star Forest Graph     7              2
     Discrete System     2              0
           Weak Form     2              0
    GraphPartitioner     1              0
              Vector    17              3
              Matrix     3              0

--- Event Stage 3: Solve

========================================================================================================================
Average time to get PetscTime(): 3.1e-08
#PETSc Option Table entries:
-log_view
-netfile datafiles/case_ACTIVSg200.m
-opflow_model POWER_BALANCE_HIOP
-opflow_solver HIOP
-print_output 0
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --prefix=/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45 --with-ssl=0 --download-c2html=0 --download-sowing=0 --download-hwloc=0 --with-make-exec=make --with-cc=/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicc --with-cxx=/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicxx --with-fc=/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpif90 --with-precision=double --with-scalar-type=real --with-shared-libraries=1 --with-debugging=0 --with-openmp=0 --with-64-bit-indices=0 --with-blaslapack-lib=/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/openblas-0.3.20-qphkv5qzud65a5duvaqxi5zvb5rc4lzf/lib/libopenblas.so --with-x=0 --with-clanguage=C --with-cuda=0 --with-hip=0 --with-metis=0 --with-hypre=0 --with-parmetis=0 --with-kokkos=0 --with-kokkos-kernels=0 --with-superlu_dist=0 --with-ptscotch=0 --with-suitesparse=0 --with-hdf5=0 --with-zlib=0 --with-mumps=0 --with-trilinos=0 --with-fftw=0 --with-valgrind=0 --with-gmp=0 --with-libpng=0 --with-giflib=0 --with-mpfr=0 --with-netcdf=0 --with-pnetcdf=0 --with-moab=0 --with-random123=0 --with-exodusii=0 --with-cgns=0 --with-memkind=0 --with-p4est=0 --with-saws=0 --with-yaml=0 --with-hwloc=0 --with-libjpeg=0 --with-scalapack=0 --with-strumpack=0 --with-mmg=0 --with-parmmg=0 --with-tetgen=0
-----------------------------------------
Libraries compiled on 2023-07-04 20:14:54 on frontier01532
Machine characteristics: Linux-5.14.21-150400.24.46_12.0.72-cray_shasta_c-x86_64-with-glibc2.31
Using PETSc directory: /lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45
Using PETSc arch:
-----------------------------------------

Using C compiler: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-unknown-pragmas -fstack-protector -Qunused-arguments -fvisibility=hidden -g -O3
Using Fortran compiler: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpif90  -fPIC -O
-----------------------------------------

Using include paths: -I/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45/include
-----------------------------------------

Using C linker: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpicc
Using Fortran linker: /opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/bin/mpif90
Using libraries: -Wl,-rpath,/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45/lib -L/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/petsc-3.18.6-x2vp3h6yfkxac23xjabse4455nzf3f45/lib -lpetsc -Wl,-rpath,/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/openblas-0.3.20-qphkv5qzud65a5duvaqxi5zvb5rc4lzf/lib -L/lustre/orion/proj-shared/csc359/sayefsakin/spack-install/linux-sles15-zen3/clang-14.0.0-rocm5.2.0/openblas-0.3.20-qphkv5qzud65a5duvaqxi5zvb5rc4lzf/lib -Wl,-rpath,/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/lib -L/opt/cray/pe/mpich/8.1.25/ofi/amd/5.0/lib -Wl,-rpath,/usr/lib64/gcc/x86_64-suse-linux/7 -L/usr/lib64/gcc/x86_64-suse-linux/7 -Wl,-rpath,/usr/x86_64-suse-linux/lib -L/usr/x86_64-suse-linux/lib -Wl,-rpath,/opt/rocm-5.2.0/llvm/lib -L/opt/rocm-5.2.0/llvm/lib -lopenblas -lpthread -lm -lstdc++ -ldl -lmpifort_amd -lmpi_amd -lflangmain -lpgmath -lflang -lflangrti -lompstub -lm -lrt -lpthread -lgcc_s -lstdc++ -ldl
-----------------------------------------

Auto Profiler Log ======> opflow runs successfully
Auto Profiler Log ======> Total measured time with no tool: 1.53801 seconds.
Auto Profiler Log ======> With no tool Total Iterations: 1, CPU Average time per testcase: 1.53801 seconds, std: 0.0
Auto Profiler Log ======> PETSc reported Solve Time per testcase: 1.2443 seconds
Auto Profiler Log ======> Total HIOP iterations: 20, Average time per HIOP iteration: 0.0769 seconds
Auto Profiler Log ======> PETSc reported Solve time per iteration: 0.06221
